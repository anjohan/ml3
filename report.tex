\documentclass[11pt,british,a4paper]{article}
%\pdfobjcompresslevel=0
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[includeheadfoot,margin=0.8 in]{geometry}
\usepackage{siunitx,physics,cancel,upgreek,varioref,listings,booktabs,pdfpages,ifthen,polynom,todonotes}
%\usepackage{minted}
\usepackage[backend=biber]{biblatex}
\DefineBibliographyStrings{english}{%
      bibliography = {References},
}
\addbibresource{sources.bib}
\usepackage{mathtools,upgreek,bigints}
\usepackage{babel}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tocloft}
\usepackage[T1]{fontenc}
%\usepackage{fouriernc}
% \usepackage[T1]{fontenc}
\usepackage{mathpazo}
% \usepackage{inconsolata}
%\usepackage{eulervm}
%\usepackage{cmbright}
%\usepackage{fontspec}
%\usepackage{unicode-math}
%\setmainfont{Tex Gyre Pagella}
%\setmathfont{Tex Gyre Pagella Math}
%\setmonofont{Tex Gyre Cursor}
%\renewcommand*\ttdefault{txtt}
\graphicspath{{figs/}}
\usepackage[scaled]{beramono}
\usepackage{fancyhdr}
\usepackage[utf8]{inputenc}
\usepackage{textcomp}
\usepackage{lastpage}
\usepackage{microtype}
\usepackage[font=normalsize]{subcaption}
\usepackage{luacode}
\usepackage[linktoc=all, bookmarks=true, pdfauthor={Anders Johansson},pdftitle={FYS-STK4155 Project 3}]{hyperref}
\usepackage{tikz,pgfplots,pgfplotstable}
\usepgfplotslibrary{colorbrewer}
\usepgfplotslibrary{external}
\tikzset{external/system call={lualatex \tikzexternalcheckshellescape -halt-on-error -interaction=batchmode -jobname "\image" "\texsource"}}
\tikzexternalize%[prefix=tmp/, mode=list and make]
\pgfplotsset{cycle list/Dark2}
\pgfplotsset{compat=1.8}
\pgfmathsetseed{12}
\renewcommand{\CancelColor}{\color{red}}
\let\oldexp=\exp
\renewcommand{\exp}[1]{\mathrm{e}^{#1}}


\labelformat{section}{#1}
\labelformat{subsection}{section~#1}
\labelformat{subsubsection}{paragraph~#1}
\labelformat{equation}{equation~(#1)}
\labelformat{figure}{figure~#1}
\labelformat{table}{table~#1}

\renewcommand{\footrulewidth}{\headrulewidth}

%\setcounter{secnumdepth}{4}
\setlength{\parindent}{0cm}
\setlength{\parskip}{1em}

\definecolor{bluekeywords}{rgb}{0.13,0.13,1}
\definecolor{greencomments}{rgb}{0,0.5,0}
\definecolor{redstrings}{rgb}{0.9,0,0}
\lstset{rangeprefix=!/,
    rangesuffix=/!,
    includerangemarker=false}
\lstset{showstringspaces=false,
    basicstyle=\small\ttfamily,
    keywordstyle=\color{bluekeywords},
    commentstyle=\color{greencomments},
    numberstyle=\color{bluekeywords},
    stringstyle=\color{redstrings},
    breaklines=true,
    %texcl=true,
    language=Fortran,
    morekeywords={norm2,class,deferred}
}
\colorlet{DarkGrey}{white!20!black}
\newcommand{\eqtag}[1]{\refstepcounter{equation}\tag{\theequation}\label{#1}}
\hypersetup{hidelinks=True}

\sisetup{detect-all}
\sisetup{exponent-product = \cdot, output-product = \cdot,per-mode=symbol}
% \sisetup{output-decimal-marker={,}}
\sisetup{round-mode = off, round-precision=3}
\sisetup{number-unit-product = \ }

\allowdisplaybreaks[4]
\fancyhf{}

\rhead{Project 3}
\rfoot{Page~\thepage{} of~\pageref{LastPage}}
\lhead{FYS-STK4155}

%\definecolor{gronn}{rgb}{0.29, 0.33, 0.13}
\definecolor{gronn}{rgb}{0, 0.5, 0}

\newcommand{\husk}[2]{\tikz[baseline,remember picture,inner sep=0pt,outer sep=0pt]{\node[anchor=base] (#1) {\(#2\)};}}
\newcommand{\artanh}[1]{\operatorname{artanh}{\qty(#1)}}
\newcommand{\matrise}[1]{\begin{pmatrix}#1\end{pmatrix}}
\DeclareMathOperator{\Proj}{Proj}
\DeclareMathOperator{\Col}{Col}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\MSE}{MSE}

\newread\infile

\setcounter{tocdepth}{2}
\numberwithin{equation}{section}

\pgfplotstableset{
    every head row/.style={before row=\toprule,after row=\midrule},
    every last row/.style={after row=\bottomrule},
    columns/Method/.style={string type, column type=l}
}

\pgfplotsset{
    tick align=outside,
    tick pos=left,
    xmajorgrids,
    x grid style={white},
    ymajorgrids,
    y grid style={white},
    axis line style={white},
    axis background/.style={fill=white!89.803921568627459!black}
}

%start
\begin{document}
\tikzexternaldisable
\title{FYS-STK4155: Project 3}
\author{Anders Johansson}
%\maketitle

\begin{titlepage}
%\includegraphics[width=\textwidth]{fysisk.pdf}
\vspace*{\fill}
\begin{center}
\textsf{
    \Huge \textbf{Project 3}\\\vspace{0.5cm}
    \Large \textbf{FYS-STK4155 --- Applied data analysis and machine learning}\\
    \vspace{8cm}
    Anders Johansson\\
    \today\\
}
\vspace{1.5cm}
\includegraphics{uio.pdf}\\
\vspace*{\fill}
\end{center}
\end{titlepage}
\null
\pagestyle{empty}
\newpage

\pagestyle{fancy}
\setcounter{page}{1}

\begin{abstract}
    Differential equations.
\end{abstract}
\pagestyle{fancy}
\thispagestyle{fancy}
\tableofcontents
\pagestyle{fancy}
\thispagestyle{fancy}

%  _       _                 _            _   _
% (_)_ __ | |_ _ __ ___   __| |_   _  ___| |_(_) ___  _ __
% | | '_ \| __| '__/ _ \ / _` | | | |/ __| __| |/ _ \| '_ \
% | | | | | |_| | | (_) | (_| | |_| | (__| |_| | (_) | | | |
% |_|_| |_|\__|_|  \___/ \__,_|\__,_|\___|\__|_|\___/|_| |_|
\section{Introduction}
Differential equations are an important tool in physics for understanding the world around us. Classical motion is determined by Newton's laws of motion, which are ordinary differential equations, while relativistic motion and quantum mechanics are summarised in partial differential equations. Unfortunately, differential equations are hard to solve analytically, and numerical techniques are therefore employed. Historically, finite difference and finite element schemes have been used with great success. This report utilises a new approach, namely artificial neural networks, and compares it with a simple finite difference scheme.

Artificial neural networks are used to solve the diffusion equation, which models such important phenomena as heat dissipation and diffusion. Tensorflow, Google's leading framework for machine learning and artificial intelligence, is used as a high-level, intuitive, ``black box'' approach. The results are compared to the simplest finite difference scheme, namely Forward Euler.

Since the main theory of neural networks was derived in an earlier project, this report mainly revolves around their application to neural networks. First, however, the report starts off with a derivation of the finite difference scheme with which the neural network is compared, before going through the details of how to use neural networks for solving differential equations. Both methods are then applied to the diffusion equation and their results are compared.

%  _   _                                             _
% | |_| |__   ___  ___  _ __ _   _    __ _ _ __   __| |
% | __| '_ \ / _ \/ _ \| '__| | | |  / _` | '_ \ / _` |
% | |_| | | |  __/ (_) | |  | |_| | | (_| | | | | (_| |
%  \__|_| |_|\___|\___/|_|   \__, |  \__,_|_| |_|\__,_|
%                 _   _      |___/    _
%  _ __ ___   ___| |_| |__   ___   __| |___
% | '_ ` _ \ / _ \ __| '_ \ / _ \ / _` / __|
% | | | | | |  __/ |_| | | | (_) | (_| \__ \
% |_| |_| |_|\___|\__|_| |_|\___/ \__,_|___/
\section{Theory and methods}
\subsection{The diffusion equation}
The standard diffusion equation is
\begin{equation}
    \pdv{u}{t} = \nabla^2 u, \quad \text{or, in one dimension,}\quad \pdv{u}{t} = \pdv[2]{u}{x},
\end{equation}
for \(x\in\qty[0,1]\) and \(t\geq0\). In this project, the initial and boundary conditions are
\begin{equation}
    u(x,0) = \sin(\pi x), \qquad u(0,t) = u(1,t) = 0.
\end{equation}
The analytical solution is obviously
\begin{equation}
    u(x,t) = \exp{-\pi^2 t} \sin(\pi x).
\end{equation}


\subsection{Finite difference methods}
Differential equations are equations where the unknown is a function, and the equation consists of terms containing the function and its derivatives. Finite difference methods simply replace the derivatives with numerical approximations based on Taylor expansions, and solve for the unknown function values.

\subsubsection{The Forward Euler scheme}
The simplest approximations to numerical derivatives which can be inserted in the diffusion equation are
\begin{equation}
    \pdv{u(x,t)}{t} \approx \frac{u(x,t+\Delta t) - u(x,t)}{\Delta t}, \qquad
    \pdv[2]{u(x,t)}{x} \approx \frac{u(x+\Delta x, t) - 2u(x,t) + u(x-\Delta x,t)}{\Delta x^2}.
\end{equation}
Discretising with \(x_i=i\Delta x\) for \(i=0,\ldots,N_x\) with \(\Delta x=1/N_x\), \(t^j=j\Delta t\) for \(j=0,\ldots,N_t\) with \(\Delta t=1/N_t\) and \(u_i^j = u(x_i,t^j)\), the diffusion equation with these approximations is
\begin{equation}
    \frac{u_i^{j+1} - u_i^j}{\Delta t} = \frac{u_{i+1}^j - 2u_i^j + u_{i-1}^j}{\Delta x^2}
\end{equation}
with boundary conditions
\begin{equation}
    u_i^0 = \sin(i\pi\Delta x),\quad
    u_0^j = u_{N_x}^j = 0.
\end{equation}
Since \(\qty{u_i^0}\) is known, the function values at the subsequent timesteps can be found recursively by
\begin{equation}
    u_i^{j+1} = u_i^j + \frac{\Delta t}{\Delta x^2} \qty(u_{i+1}^j - 2u_i^j + u_{i-1}^j)
\end{equation}
for \(i=1,\ldots,N_x-1\). The error terms are proportional to \(\Delta t\) and \(\Delta x^2\) due to a first order approximation to the temporal derivative and a second order approximation to the spatial derivative. Stability is ensured\cite{tveito} when
\begin{equation}
    \frac{\Delta t}{\Delta x^2} \leq \frac{1}{2},
\end{equation}
so \(\Delta t = \tfrac{1}{2}\Delta x^2\) is used.

\subsection{Neural networks for differential equations}
A neural network can approximate any function, and it should therefore also be able to approximate the solution of a differential equation such as the diffusion equation. The neural network approximates by minimising a cost function, and the challenge is therefore to find a suitable cost function.

The simplest approach is simply to use the square of the difference between the two sides of the diffusion equation as the cost function,
\begin{equation}
    Q = \qty(\pdv{u}{t} - \pdv[2]{u}{x})^2.
\end{equation}
It seems difficult to differentiate this cost function with respect to the weights and biases of the neural network. I have therefore chosen to use Tensorflow for this project, since it contains functionality for calculating automatic derivatives (something my otherwise brilliant Fortran network lacks).

Another difficulty is to fulfill the initial and boundary conditions. One approach may be to add terms to the cost function which penalise approximations which do not fulfill the initial and boundary conditions. Another approach, which is found more often in literature\cite{nnde} and therefore employed in this report, is to not use the output of the neural network directly, but rather combining a neural network with other functions in such a way that the initial and boundary conditions are guaranteed to be fulfilled.

In the case of the diffusion equation with our set of conditions, a natural choice is
\begin{equation}
    u(x,t) = \sin(\pi x) + tx\qty(1-x)n(x,t),
\end{equation}
where \(n(x,t)\) is the output from the neural network.

%                      _ _
%  _ __ ___  ___ _   _| | |_ ___
% | '__/ _ \/ __| | | | | __/ __|
% | | |  __/\__ \ |_| | | |_\__ \
% |_|  \___||___/\__,_|_|\__|___/
\section{Results}
\subsection{Forward Euler}
\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                thick,
                width=\textwidth,
                height=2.5in,
                xlabel={\(x\)},
                ylabel={\(u(x,t)\)},
                legend style={draw=none,fill=none,at={(-0.01,1.03)}, anchor=north west},
                legend cell align=left,
                samples=100
            ]
                \addplot+[mark=none, gray, domain=0:1] {exp(-pi*pi*0.2)*sin(deg(pi*x))};
                \addlegendentry{\(\exp{-\pi^2 t}\sin(\pi x)\)};
                \addplot+[mark=none] table[y index=1] {data/euler_2.0E-01.dat};
                \addlegendentry{\(t=\num{0.0}\)};
                \addplot+[mark=none] table[y index=2] {data/euler_2.0E-01.dat};
                \addlegendentry{\(t=\num{0.1}\)};
                \addplot+[mark=none] table[y index=3] {data/euler_2.0E-01.dat};
                \addlegendentry{\(t=\num{0.2}\)};
                \addplot+[mark=none, gray, domain=0:1] {sin(deg(pi*x))};
                \addplot+[mark=none, gray, domain=0:1] {exp(-pi*pi*0.1)*sin(deg(pi*x))};
            \end{axis}
        \end{tikzpicture}
        \caption{\(\Delta x=\num{2e-1}\)}
    \end{subfigure}
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                thick,
                width=\textwidth,
                height=2.5in,
                xlabel={\(x\)},
                ylabel={\(u(x,t)\)},
                legend style={draw=none,fill=none,at={(0.98,0.98)}, anchor=north east},
                legend cell align=left,
            ]
                \addplot+[mark=none] table[y index=1] {data/euler_1.0E-02.dat};
                \addlegendentry{\(t=\num{0.0}\)};
                \addplot+[mark=none] table[y index=2] {data/euler_1.0E-02.dat};
                \addlegendentry{\(t=\num{0.1}\)};
                \addplot+[mark=none] table[y index=3] {data/euler_1.0E-02.dat};
                \addlegendentry{\(t=\num{0.2}\)};
            \end{axis}
        \end{tikzpicture}
        \caption{\(\Delta x=\num{1e-2}\)}
    \end{subfigure}
    \caption{Results from solving the diffusion equation with the Forward Euler finite difference scheme for two different values of \(\Delta x\) and \(\Delta t=\frac{1}{2}\Delta x^2\). While the solution for \(\Delta x=\num{0.02}\) deviates visibly from the analytic solution, \(\Delta x=\num{0.01}\) gives a good approximation to the analytic solution.}
\end{figure}



%                                   _ _
%   __ _ _ __  _ __   ___ _ __   __| (_)_  __
%  / _` | '_ \| '_ \ / _ \ '_ \ / _` | \ \/ /
% | (_| | |_) | |_) |  __/ | | | (_| | |>  <
%  \__,_| .__/| .__/ \___|_| |_|\__,_|_/_/\_\
%       |_|   |_|
\clearpage
\appendix
\part*{Appendix}
\addcontentsline{toc}{part}{Appendix}
\renewcommand{\thesection}{\Alph{section}}
\labelformat{section}{appendix~#1}
\labelformat{subsection}{appendix~#1}


\clearpage
\nocite{*}
\printbibliography{}
\addcontentsline{toc}{section}{\bibname}
\end{document}
