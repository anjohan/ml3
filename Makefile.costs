activation_functions = sigmoid relu tanh
learning_rates = 0.0001 0.0001 0.001 0.01 0.1 1
momentums = 0.0001 0.0001 0.001 0.01 0.1 1
u_guesses = 1 2

optimisers = $(foreach learning_rate,$(learning_rates),\
			   $(foreach momentum,$(momentums),\
			     $(learning_rate),$(momentum))) Adam

architectures = 10 10,10 10,10,10 10,10,10,10 10,10,10,10,10 10,10,10,10,10,10 \
				10,10,10,10,10,10,10 10,10,10,10,10,10,10,10 \
				1000 100 100,100 100,10,10 10,100,10 10,10,100 100,100,100

define setsinglecosts
single_costs_$(1) = $(foreach activation_function,$(activation_functions),\
			          $(foreach optimiser,$(optimisers),\
				        $(foreach architecture,$(architectures),\
				          data/nn_cost_$(activation_function)_$(optimiser)_$(architecture)_$(1).dat)))
endef
$(foreach u_guess,$(u_guesses),$(eval $(call setsinglecosts,$(u_guess))))

define nncost
data/nn_costs_$(1).dat: $$(single_costs_$(1))
	cat $$^ > $$@
endef
$(foreach u_guess,$(u_guesses),$(eval $(call nncost,$(u_guess))))

data/nn_cost_%.dat: programs/nn_params.py
	python $< $*
